2_w_v0_llama3_no_ex:
  batch_size: 1
  completion_parser_kwargs:
    matcher:
      A: 1.0
      B: 2.0
      tie: 0.0
  completions_kwargs:
    max_new_tokens: 100
    model_kwargs:
      torch_dtype: float16
    model_name: meta-llama/Meta-Llama-3-8B-Instruct
    temperature: 0
  fn_completion_parser: match_parser
  fn_completions: huggingface_local_completions
  prompt_template: templates_generated/2_w_v0_llama3_no_ex.txt
